<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Hexo
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 6.3.0"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">MICCALL</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="个人">
		                个人
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="团队">
		                团队
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="图库">
		                图库
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="标签">
		                标签
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/miccall" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://qilin-static.s3.cn-northwest-1.amazonaws.com.cn/sandog/zhilang2.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >基于FlinkCDC + Hudi 实时数据同步系统</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="基于FlinkCDC-Hudi-实时数据同步系统"><a href="#基于FlinkCDC-Hudi-实时数据同步系统" class="headerlink" title="基于FlinkCDC + Hudi 实时数据同步系统"></a>基于FlinkCDC + Hudi 实时数据同步系统</h1><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><p><img src="https://qilin-static.s3.cn-northwest-1.amazonaws.com.cn/sandog/WechatIMG90.jpeg" alt="data-flow"></p>
<p>数据由 Flink CDC 从业务数据库(Mysql&#x2F;MongoDB) 抽取，sink到 Kafka中，由 Spark stream 从kafka中读取出来，由hudi 写入到 S3</p>
<h2 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h2><h3 id="FlinkCDC"><a href="#FlinkCDC" class="headerlink" title="FlinkCDC"></a>FlinkCDC</h3><p>Flink CDC Connectors 是 Apache Flink的一个source端的连接器，目前支持从 MySQL ，Oracle, MongoDB等数据源。</p>
<p>Flink CDC 底层封装了 Debezium， Debezium 同步一张表会分为两个阶段：</p>
<ul>
<li>全量阶段：查询当前表中所有记录</li>
<li>增量阶段：从 binlog 消费变更数据</li>
</ul>
<p>Flink CDC 实现了无锁、支持水平扩展和checkpoint。而 Flink CDC 实现无锁，主要是参考 Netflix 的 DBlog 论文里描述的无锁算法，该算法的核心思想是在划分了 Chunk 后，对于每个 Chunk 的全量读取和增量读取，在不用锁的条件下完成一致性的合并。</p>
<p>由于该算法需要在数据库中维护一张信号表，再通过信号表在 binlog 文件中打点，记录低点位和高点位。因此Flink CDC 结合自身的情况，在 Chunk 读取算法上做了去信号表的改进，不需要额外维护信号表，通过直接读取 binlog 位点替代在 binlog 中做标记的功能。整体流程可以概括为：</p>
<p>首先通过主键对表进行 Snapshot Chunk 划分，再将 Snapshot Chunk 分发给多个 SourceReader，每个 Snapshot Chunk 读取时通过算法实现无锁条件下的一致性读，SourceReader 读取时支持 chunk 粒度的 checkpoint，在所有 Snapshot Chunk 读取完成后，下发一个 binlog chunk 进行增量部分的 binlog 读取，这便是 Flink CDC 2.0 的整体流程，如下图所示：</p>
<p><img src="https://qilin-static.s3.cn-northwest-1.amazonaws.com.cn/sandog/flink-cdc.png" alt="data-flow"></p>
<ul>
<li>全程无锁，不会对数据库产生需要加锁所带来的风险</li>
<li>多并行度，全量数据的读取阶段支持水平扩展，使亿级别的大表可以通过加大并行度来加快读取速度</li>
<li>断点续传，全量阶段支持checkpoint，即使任务因某种原因退出了，也可通过保存的checkpoint对任务进行恢复实现数据的断点续传</li>
</ul>
<h3 id="Hudi"><a href="#Hudi" class="headerlink" title="Hudi"></a>Hudi</h3><p>Apache Hudi目前被业内描述为围绕数据库内核构建的流式数据湖平台（Streaming Data Lake Platform）</p>
<h4 id="Hudi-的表类型"><a href="#Hudi-的表类型" class="headerlink" title="Hudi 的表类型"></a>Hudi 的表类型</h4><ul>
<li>COW：使用parquet文件格式存储数据。通过在写入期间执行同步合并，更新文件版本和重写文件。</li>
<li>MOR：使用parquet +avro文件格式的组合存储数据。将数据记录到增量log文件中，然后以同步或异步方式压缩生成新版本的parquet 文件。</li>
</ul>
<h4 id="Hudi的三种写入类型"><a href="#Hudi的三种写入类型" class="headerlink" title="Hudi的三种写入类型"></a>Hudi的三种写入类型</h4><ul>
<li>UPSERT：默认行为，数据先通过 index 打标(INSERT&#x2F;UPDATE)，有一些启发式算法决定消息的组织以优化文件的大小 &#x3D;&gt; CDC 导入</li>
<li>INSERT：跳过 index，写入效率更高 &#x3D;&gt; Log Deduplication</li>
<li>BULK_INSERT：写排序，对大数据量的 Hudi 表初始化友好，对文件大小的限制 best effort（写 HFile）</li>
</ul>
<h4 id="Hudi的核心优势"><a href="#Hudi的核心优势" class="headerlink" title="Hudi的核心优势"></a>Hudi的核心优势</h4><ul>
<li>写入过程充分优化了文件存储的小文件问题，Copy On Write 写会一直将一个 bucket （FileGroup）的 base 文件写到设定的阈值大小才会划分新的 bucket；Merge On Read 写在同一个 bucket 中，log file 也是一直 append 直到大小超过设定的阈值 roll over。</li>
<li>对 UPDATE 和 DELETE 的支持非常高效，一条 record 的整个生命周期操作都发生在同一个 bucket，不仅减少小文件数量，也提升了数据读取的效率（不必要的 join 和 merge）</li>
</ul>
<h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><h3 id="Spark-Stream-读取-kafka-写入hudi"><a href="#Spark-Stream-读取-kafka-写入hudi" class="headerlink" title="Spark Stream 读取 kafka 写入hudi"></a>Spark Stream 读取 kafka 写入hudi</h3><p>CDC数据到了Kafka之后，通过Spark计算引擎消费数据写入到Hudi表，我们把这一层我们称之为ODS层。无论Spark还是Flink都可以做到数据ODS层的数据落地，使用哪一个我们需要综合考量，这里阐述一些相对重要的点。首先对于Spark引擎，我们一定是使用Spark Structured Streaming 消费kfaka写入Hudi，由于可以使用DataFrame API写Hudi, 因此在Spark中可以方便的实现消费CDC Topic并根据其每条数据中的元信息字段(数据库名称，表名称等)在单作业内分流写入不同的Hudi表，封装多表并行写入逻辑，一个Job即可实现整库多表同步的逻辑。</p>
<ol>
<li>定义读取kafka 消息的Spark stream 的上下文。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">val df = SparkHelper.getSparkSession(params.env)</span><br><span class="line">  .readStream</span><br><span class="line">  .format(&quot;kafka&quot;)</span><br><span class="line">  .option(&quot;kafka.bootstrap.servers&quot;, params.brokerList)</span><br><span class="line">  .option(&quot;subscribe&quot;, params.sourceTopic)</span><br><span class="line">  .option(&quot;startingOffsets&quot;, value = &quot;latest&quot;)</span><br><span class="line">  .option(&quot;failOnDataLoss&quot;, value = false)</span><br><span class="line">  .option(&quot;maxOffsetsPerTrigger&quot;, params.maxOffset.toLong)</span><br><span class="line">  .option(&quot;kafka.consumer.commit.groupid&quot;, params.consumerGroup)</span><br><span class="line">  .load()</span><br><span class="line">  .repartition(Integer.valueOf(params.partitionNum))</span><br></pre></td></tr></table></figure>
<p>这里我们定义一个流式读取kafka消息的 spark stream 上下文，值得注意的是startingOffsets配置，这里一般设置为 latest，即每次都从最新的kafka消息读取，这里因为有checkpoint 存在，所以就算每次都是读取最新的，每次启动也会从上次结束的kakfa消息偏移量开始读取，不会漏掉消息。</p>
<ol start="2">
<li>定义kafka消息的Model和解析函数。<br>由 Flink cdc 丢到 kafka 里的消息，是形如如此的json串。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;before&quot;: &#123;</span><br><span class="line">		&quot;id&quot;: 100,</span><br><span class="line">		&quot;recharge_amount&quot;: 0.0,</span><br><span class="line">		&quot;membership_id&quot;: 100,</span><br><span class="line">		&quot;updated_at&quot;: 1682014813316</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;after&quot;: &#123;</span><br><span class="line">		&quot;id&quot;: 100,</span><br><span class="line">		&quot;recharge_amount&quot;: 1.0,</span><br><span class="line">		&quot;membership_id&quot;: 100,</span><br><span class="line">		&quot;updated_at&quot;: 1683373015244</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;source&quot;: &#123;</span><br><span class="line">		&quot;version&quot;: &quot;1.5.4.Final&quot;,</span><br><span class="line">		&quot;connector&quot;: &quot;mysql&quot;,</span><br><span class="line">		&quot;name&quot;: &quot;mysql_binlog_source&quot;,</span><br><span class="line">		&quot;ts_ms&quot;: 1683344215000,</span><br><span class="line">		&quot;snapshot&quot;: &quot;false&quot;,</span><br><span class="line">		&quot;db&quot;: &quot;zaihui&quot;,</span><br><span class="line">		&quot;sequence&quot;: null,</span><br><span class="line">		&quot;table&quot;: &quot;xxx&quot;,</span><br><span class="line">		&quot;server_id&quot;: 2304969070,</span><br><span class="line">		&quot;gtid&quot;: &quot;105d3aff-cb7b-11ed-9132-0c42a1b706c6:38118061&quot;,</span><br><span class="line">		&quot;file&quot;: &quot;mysql-bin.001563&quot;,</span><br><span class="line">		&quot;pos&quot;: 44088572,</span><br><span class="line">		&quot;row&quot;: 0,</span><br><span class="line">		&quot;thread&quot;: null,</span><br><span class="line">		&quot;query&quot;: null</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;op&quot;: &quot;u&quot;,</span><br><span class="line">	&quot;ts_ms&quot;: 1683344215386,</span><br><span class="line">	&quot;transaction&quot;: null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>这里我们定义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">case class HudiDebeziumDataModel(</span><br><span class="line">                                  database: String,</span><br><span class="line">                                  table: String,</span><br><span class="line">                                  operationType: String,</span><br><span class="line">                                  data: String</span><br><span class="line">                                )                             </span><br><span class="line">def debezium2Hudi(debeziumSourceData: String): HudiDebeziumDataModel = &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      require(debeziumSourceData.nonEmpty, &quot;debezium data can not be null&quot;)</span><br><span class="line">      val debeziumObject = JsonUtil.mapper.readValue(debeziumSourceData, classOf[DebeziumDataModel])</span><br><span class="line">      require(debeziumObject != null, &quot;debezium object can not be null&quot;)</span><br><span class="line">      require(debeziumObject.op.nonEmpty, &quot;debezium op type  can not be null &quot;)</span><br><span class="line">      if (!allowDebeziumOP.contains(debeziumObject.op)) &#123;</span><br><span class="line">        return null</span><br><span class="line">      &#125;</span><br><span class="line">      val hudiOp = debeziumOP2HudiOP(debeziumObject.op)</span><br><span class="line">      if (hudiOp == HudiOP.DELETE) &#123;</span><br><span class="line">        if (debeziumObject.before == null) &#123;</span><br><span class="line">          return null</span><br><span class="line">        &#125;</span><br><span class="line">        return HudiDebeziumDataModel(</span><br><span class="line">          debeziumObject.source(&quot;db&quot;),</span><br><span class="line">          debeziumObject.source(&quot;table&quot;),</span><br><span class="line">          hudiOp,</span><br><span class="line">          JsonUtil.toJson(debeziumObject.before)</span><br><span class="line">        )</span><br><span class="line">      &#125; else if (hudiOp == HudiOP.INSERT || hudiOp == HudiOP.UPSERT) &#123;</span><br><span class="line">        if (debeziumObject.after == null) &#123;</span><br><span class="line">          return null</span><br><span class="line">        &#125;</span><br><span class="line">        return HudiDebeziumDataModel(</span><br><span class="line">          debeziumObject.source(&quot;db&quot;),</span><br><span class="line">          debeziumObject.source(&quot;table&quot;),</span><br><span class="line">          debeziumOP2HudiOP(debeziumObject.op),</span><br><span class="line">          JsonUtil.toJson(debeziumObject.after)</span><br><span class="line">        )</span><br><span class="line">      &#125;</span><br><span class="line">      null</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Exception =&gt;</span><br><span class="line">        log.error(&quot;parse debezium json error&quot;, e)</span><br><span class="line">        null</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>消费kafka消息，生成 DataFrame 写入到hudi</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">private def writeToHudi(df: DataFrame, params: Config, tableInfo: TableInfo, props: mutable.Map[String, String]): Unit = &#123;</span><br><span class="line">  try &#123;</span><br><span class="line">    df.write.format(&quot;org.apache.hudi&quot;)</span><br><span class="line">      .options(props)</span><br><span class="line">      .mode(SaveMode.Append)</span><br><span class="line">      .save(params.hudiEventBasePath + tableInfo.hiveDatabase + &quot;/&quot; + tableInfo.hudiTable + &quot;/&quot;)</span><br><span class="line">  &#125; catch &#123;</span><br><span class="line">    case e: Exception =&gt;</span><br><span class="line">      println(&quot;writeToHudi error dataframe:&quot;)</span><br><span class="line">      df.show()</span><br><span class="line">      println(&quot;writeToHudi error&quot;, e)</span><br><span class="line">      log.error(&quot;writeToHudi error&quot;, e)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>设置hudi的写入参数</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">private def setDefaultConfig(params: Config, tableInfo: TableInfo): mutable.Map[String, String] = &#123;</span><br><span class="line">  val props = new mutable.HashMap[String, String]</span><br><span class="line">  if (&quot;true&quot;.equalsIgnoreCase(params.syncHive)) &#123;</span><br><span class="line">    props.put(&quot;hoodie.datasource.hive_sync.enable&quot;, &quot;true&quot;)</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    props.put(&quot;hoodie.datasource.hive_sync.enable&quot;, &quot;false&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  params.tableType.toUpperCase() match &#123;</span><br><span class="line">    case &quot;COW&quot; =&gt;</span><br><span class="line">      props.put(&quot;hoodie.datasource.write.table.type&quot;, &quot;COPY_ON_WRITE&quot;)</span><br><span class="line">    case &quot;MOR&quot; =&gt;</span><br><span class="line">      props.put(&quot;hoodie.datasource.write.table.type&quot;, &quot;MERGE_ON_READ&quot;)</span><br><span class="line">      props.put(&quot;hoodie.compact.inline&quot;, params.morCompact)</span><br><span class="line">      props.put(&quot;hoodie.compact.inline.max.delta.commits&quot;, params.inlineMax)</span><br><span class="line">    case _ =&gt;</span><br><span class="line">      props.put(&quot;hoodie.datasource.write.table.type&quot;, &quot;COPY_ON_WRITE&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  props.put(&quot;hoodie.table.name&quot;, tableInfo.hudiTable)</span><br><span class="line">  // 设置表的主键</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.recordkey.field&quot;, tableInfo.recordKey)</span><br><span class="line">  // 设置表的主键融合参数，当主键冲突的时候，便以此参数做融合，一般用数据的update time</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.precombine.field&quot;, tableInfo.precombineKey)</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.partitionpath.field&quot;, tableInfo.hudiPartitionField)</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.keygenerator.class&quot;, &quot;org.apache.hudi.keygen.ComplexKeyGenerator&quot;)</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.payload.class&quot;, &quot;org.apache.hudi.common.model.DefaultHoodieRecordPayload&quot;)</span><br><span class="line">  props.put(&quot;hoodie.clean.async&quot;, &quot;true&quot;)</span><br><span class="line">  props.put(&quot;hoodie.clean.automatic&quot;, &quot;true&quot;)</span><br><span class="line">  props.put(&quot;hoodie.cleaner.commits.retained&quot;, &quot;2&quot;)</span><br><span class="line">  props.put(&quot;hoodie.keep.min.commits&quot;, &quot;5&quot;)</span><br><span class="line">  props.put(&quot;hoodie.keep.max.commits&quot;, &quot;6&quot;)</span><br><span class="line">  props.put(&quot;hoodie.datasource.write.nulls_as_empty_string&quot;, &quot;false&quot;)</span><br><span class="line">  // hive 同步相关配置</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.database&quot;, tableInfo.hiveDatabase)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.table&quot;, tableInfo.hudiTable)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.mode&quot;, params.syncMode)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.metastore.uris&quot;, params.syncMetastore)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.partition_fields&quot;, tableInfo.hudiPartitionField)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.jdbcurl&quot;, params.syncJDBCUrl)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.partition_extractor_class&quot;, &quot;org.apache.hudi.hive.MultiPartKeysValueExtractor&quot;)</span><br><span class="line">  props.put(&quot;hoodie.datasource.hive_sync.username&quot;, params.syncJDBCUsername)</span><br><span class="line"></span><br><span class="line">  if (!&quot;&quot;.equalsIgnoreCase(params.hudiConf)) &#123;</span><br><span class="line">    val kvArray = params.hudiConf.split(&quot;,&quot;)</span><br><span class="line">    for (kv &lt;- kvArray) &#123;</span><br><span class="line">      val tmp = kv.split(&quot;=&quot;)</span><br><span class="line">      props.put(tmp(0), tmp(1))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  props</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://example.com/2023/06/17/%E5%9F%BA%E4%BA%8EFlinkCDC%20+%20Hudi%20%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://example.com/2023/06/17/%E5%9F%BA%E4%BA%8EFlinkCDC%20+%20Hudi%20%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a target="_blank" rel="noopener" href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
